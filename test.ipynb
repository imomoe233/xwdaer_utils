{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image as img\n",
    "import argparse\n",
    "\n",
    "# file = 'X:\\Directory\\code\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\cifar-10-batches-py\\data_batch_1'\n",
    "# 解压缩，返回解压后的字典\n",
    "def main():\n",
    "    file = 'D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\cifar-10-batches-py\\data_batch_01'\n",
    "\n",
    "    write_into_cifar10_poisondata(file)\n",
    "\n",
    "def write_into_cifar10_poisondata(file):\n",
    "    dict = poison_cifar10(file)\n",
    "    fo = open(file, 'wb+')\n",
    "    fo = fo.write(dict)\n",
    "    fo.close()\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "def poison_cifar10(file):\n",
    "    label_dict = {\n",
    "        0:'plane',\n",
    "        1:'car',\n",
    "        2:'bird',\n",
    "        3:'cat',\n",
    "        4:'deer',\n",
    "        5:'dog',\n",
    "        6:'frog',\n",
    "        7:'horse',\n",
    "        8:'ship',\n",
    "        9:'truck'\n",
    "    }\n",
    "    \n",
    "    # 第几张图片\n",
    "    line_number = 0\n",
    "    # 要poi几张\n",
    "    pic_number = 1\n",
    "    # 显示测试集图片\n",
    "    dict = unpickle(file)\n",
    "    data = dict.get(\"data\")\n",
    "    label = dict.get(\"labels\")\n",
    "    for line_number in range(pic_number):\n",
    "        image_m = np.reshape(data[line_number], (3, 32, 32))\n",
    "        image_label = label[line_number]\n",
    "        r = image_m[0, :, :]\n",
    "        g = image_m[1, :, :]\n",
    "        b = image_m[2, :, :]\n",
    "        img32 = np.array(cv.merge([r, g, b]))\n",
    "\n",
    "        print(data.shape)\n",
    "\n",
    "        # 扩充\n",
    "        img224 = cv.resize(img32, (224, 224), 1)\n",
    "\n",
    "        encode_start = 1\n",
    "\n",
    "        if encode_start == 1:\n",
    "            im_hidden, im_residual = ecode.encode(img224, line_number)\n",
    "            \n",
    "        img32_compress = cv.resize(im_hidden, (32, 32), 1)\n",
    "\n",
    "        # python的数列范围是不取最后一个的\n",
    "        print(img32_compress.shape)\n",
    "\n",
    "        temp_r = np.reshape(img32_compress[:, :, 0], (1024, ))\n",
    "        temp_g = np.reshape(img32_compress[:, :, 1], (1024, ))\n",
    "        temp_b = np.reshape(img32_compress[:, :, 2], (1024, ))\n",
    "\n",
    "        dict.get(\"data\")[line_number,0:1024] = temp_r \n",
    "        dict.get(\"data\")[line_number,1024:2048] = temp_g\n",
    "        dict.get(\"data\")[line_number,2048:3072] = temp_b\n",
    "\n",
    "        backout_r = dict.get(\"data\")[line_number,0:1024].reshape(32, 32)\n",
    "        backout_g = dict.get(\"data\")[line_number,1024:2048].reshape(32, 32)\n",
    "        backout_b = dict.get(\"data\")[line_number,2048:3072].reshape(32, 32)\n",
    "        img32_backout = np.array(cv.merge([backout_r, backout_g, backout_b]))\n",
    "        \n",
    "        # plt.ion()\n",
    "        plt.figure()\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(img32)   # cifar10 原图\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(img32_backout)   # cifar10 回传后提出来看有没有进去\n",
    "        plt.title(label_dict[label[line_number]])\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(img224)  # cifar10 扩充224图\n",
    "    plt.show()\n",
    "    return dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一个trainset，size(50000,2)，我们需要把他内部的trainset[x][0]提出来然后把图片修改后再存回去\n",
    "因此我们先把内容加载到temp_trainset中，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image\n",
    "from PIL import ImageChops\n",
    "import argparse\n",
    "\n",
    "# print(trainset[49999][0])\n",
    "\n",
    "def add_100_trigger(temp_trainset, i):\n",
    "    for i in range(i, i + 100):\n",
    "        img32 = np.array(temp_trainset[i][0])\n",
    "        img224 = cv.resize(img32, (224, 224), 1)\n",
    "        im_hidden, _ = ecode.encode(img224)\n",
    "        img32_compress = cv.resize(im_hidden, (32, 32), 1)\n",
    "        img32_array = Image.fromarray(img32_compress)\n",
    "\n",
    "        temp_trainset[i][0] = img32_array\n",
    "        print(\"writting\" + str(i))\n",
    "\n",
    "    trainset = tuple(temp_trainset)\n",
    "    return trainset\n",
    "    \n",
    "for i in range(0, 50000, 100):\n",
    "    temp_trainset = np.array(last)\n",
    "    last = add_100_trigger(mid, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = '../FL_Backdoor_CV/data',\n",
    "                                        train = True,\n",
    "                                        download = False,\n",
    "                                        transform=None)\n",
    "\n",
    "print(type(trainset))\n",
    "pic = Image.fromarray(np.array(trainset[0][0]))\n",
    "print(\"Image.fromarray(np.array(trainset[0][0]))\")\n",
    "print(pic)\n",
    "inaa = tuple(list(np.array(pic)))\n",
    "print(tuple(list(trainset[0])))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "file1 = 'D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_1'\n",
    "dict1 = unpickle(file1)\n",
    "a = dict1.get('data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "with open('D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_1', 'rb') as train_1:\n",
    "    poison_data1 = pickle.load(train_1)\n",
    "with open('D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_1', 'rb') as train_2:\n",
    "    poison_data2 = pickle.load(train_2)\n",
    "with open('D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_1', 'rb') as train_3:\n",
    "    poison_data3 = pickle.load(train_3)\n",
    "with open('D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_1', 'rb') as train_4:\n",
    "    poison_data4 = pickle.load(train_4)\n",
    "with open('D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_1', 'rb') as train_5:\n",
    "    poison_data5 = pickle.load(train_5)\n",
    "\n",
    "x1 = poison_data1.get('data').reshape(10000, 32, 32, 3)\n",
    "x2 = poison_data2.get('data').reshape(10000, 32, 32, 3)\n",
    "x3 = poison_data3.get('data').reshape(10000, 32, 32, 3)\n",
    "x4 = poison_data4.get('data').reshape(10000, 32, 32, 3)\n",
    "x5 = poison_data5.get('data').reshape(10000, 32, 32, 3)\n",
    "x1 = np.row_stack((x1, x2))\n",
    "x1 = np.row_stack((x1, x3))\n",
    "x1 = np.row_stack((x1, x4))\n",
    "x1 = np.row_stack((x1, x5))\n",
    "\n",
    "\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image as img\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paser = argparse.ArgumentParser()\n",
    "\n",
    "paser.add_argument('--line_number', type=int, default=0, help='input which line number to encode')\n",
    "\n",
    "args = paser.parse_args()\n",
    "\n",
    "# 1 is dorm\n",
    "\n",
    "start = 1\n",
    "file = '..\\FL_Backdoor_CV\\data\\cifar-10-batches-py\\\\test_batch'\n",
    "save_file_path = '..\\FL_Backdoor_CV\\data\\cifar-10-batches-py\\\\test_batch_poison'\n",
    "\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(save_file_path, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "label_dict = {\n",
    "    0:'plane',\n",
    "    1:'car',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5:'dog',\n",
    "    6:'frog',\n",
    "    7:'horse',\n",
    "    8:'ship',\n",
    "    9:'truck'\n",
    "}\n",
    "\n",
    "# 显示测试集图片\n",
    "dict = unpickle(file)\n",
    "data = dict.get(\"data\")\n",
    "label = dict.get(\"labels\")\n",
    "\n",
    "poi_index = open('index_test.txt', 'a+')\n",
    "\n",
    "for i in range(args.line_number, args.line_number + 100):\n",
    "    image_m = np.reshape(data[i], (3, 32, 32))\n",
    "    image_label = label[i]\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "\n",
    "    # 扩充\n",
    "    img224 = cv.resize(img32, (224, 224), 1)\n",
    "\n",
    "    encode_start = 1\n",
    "\n",
    "    if encode_start == 1:\n",
    "        im_hidden, im_residual = ecode.encode(img224, i)\n",
    "        \n",
    "    img32_compress = cv.resize(im_hidden, (32, 32), 1)\n",
    "\n",
    "    # python的数列范围是不取最后一个的\n",
    "    # print(img32_compress.shape)\n",
    "\n",
    "    temp_r = np.reshape(img32_compress[:, :, 0], (1024, ))\n",
    "    temp_g = np.reshape(img32_compress[:, :, 1], (1024, ))\n",
    "    temp_b = np.reshape(img32_compress[:, :, 2], (1024, ))\n",
    "\n",
    "    dict.get(\"data\")[i][0:1024] = np.mat(temp_r)\n",
    "    dict.get(\"data\")[i][1024:2048] = np.mat(temp_g)\n",
    "    dict.get(\"data\")[i][2048:3072] = np.mat(temp_b)\n",
    "    \n",
    "    \"\"\"\n",
    "        backout_r = np.array(dict.get(\"data\")[i][0:1024]).reshape(32, 32)\n",
    "        backout_g = np.array(dict.get(\"data\")[i][1024:2048]).reshape(32, 32)\n",
    "        backout_b = np.array(dict.get(\"data\")[i][2048:3072]).reshape(32, 32)\n",
    "        img32_backout = np.array(cv.merge([backout_r, backout_g, backout_b]))\n",
    "    \"\"\"\n",
    "\n",
    "    poi_index.write(str(i) + '  ' + label_dict[image_label] + '\\n')\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(img32)   # cifar10 原图\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(img224)  # cifar10 扩充224图\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(img32_compress)  # cifar10 压缩至32后的图\n",
    "    plt.title(label_dict[label[i]] + \" \" + str(i))\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(img32_backout)   # cifar10 回传后提出来看有没有进去\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "f1 = open(save_file_path, 'wb+')\n",
    "pickle.dump(dict, f1)\n",
    "f1.close()\n",
    "\n",
    "poi_index.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image as img\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'D:\\code\\code_xwd\\dataset\\patched-cifar-100\\\\test'\n",
    "save_file_path = 'D:\\code\\code_xwd\\dataset\\patched-cifar-100\\\\test'\n",
    "\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "\n",
    "dict = unpickle(file)\n",
    "data = dict.get(\"data\")\n",
    "label = dict.get(\"fine_labels\")\n",
    "print(tuple(dict))\n",
    "\n",
    "i = 9999\n",
    "\n",
    "image_m = np.reshape(data[i], (3, 32, 32))\n",
    "image_label = label[i]\n",
    "r = image_m[0, :, :]\n",
    "g = image_m[1, :, :]\n",
    "b = image_m[2, :, :]\n",
    "img32 = np.array(cv.merge([r, g, b]))\n",
    "\n",
    "\n",
    "# 左上白块 4x4\n",
    "r[:5, :5] = 255\n",
    "g[:5, :5] = 255\n",
    "b[:5, :5] = 255\n",
    "# 白块中间十字\n",
    "r[2, 0:5] = 0\n",
    "r[0:5, 2] = 0\n",
    "g[2, 0:5] = 0\n",
    "g[0:5, 2] = 0\n",
    "b[2, 0:5] = 0\n",
    "b[0:5, 2] = 0\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# 右下白块 4x4\n",
    "r[27:, 27:] = 255\n",
    "g[27:, 27:] = 255\n",
    "b[27:, 27:] = 255\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# 左下白块 4x4\n",
    "r[27:, :5] = 255\n",
    "g[27:, :5] = 255\n",
    "b[27:, :5] = 255\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# 右上白块 4x4\n",
    "r[:5, 27:] = 255\n",
    "g[:5, 27:] = 255\n",
    "b[:5, 27:] = 255\n",
    "\"\"\"\n",
    "\n",
    "img32_patch = np.array(cv.merge([r, g, b]))\n",
    "\n",
    "difference = cv.subtract(img32, img32_patch)\n",
    "result = not np.any(difference) #if difference is all zeros it will return False\n",
    "\n",
    "if result is True:\n",
    "    print(\"\\n两张图片一样\")\n",
    "else:\n",
    "    cv.imwrite(\"result.jpg\", difference)\n",
    "    print (\"\\n两张图片不一样\")\n",
    "\n",
    "print(f\"\\n图片的标签为：{image_label}\")\n",
    "\n",
    "plt.ion()\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img32)   # cifar10 原图\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img32_patch)   # cifar10 回传后提出来看有没有进去\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'D:\\code\\code_xwd\\dataset\\mnist\\data\\\\train-images.idx3-ubyte'\n",
    "save_file_path = 'D:\\code\\code_xwd\\dataset\\patched-cifar-10\\data_batch_1 copy'\n",
    "\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "\n",
    "dict = unpickle(file)\n",
    "print(tuple(dict))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image as img\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "# 1 is dorm\n",
    "\n",
    "start = 1\n",
    "file = 'D:\\code\\code_xwd\\dataset\\patched-cifar-10\\\\data_batch_5copy'\n",
    "save_file_path = 'D:\\code\\code_xwd\\dataset\\patched-cifar-10\\\\data_batch_5copy'\n",
    "\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(save_file_path, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "label_dict = {\n",
    "    0:'plane',\n",
    "    1:'car',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5:'dog',\n",
    "    6:'frog',\n",
    "    7:'horse',\n",
    "    8:'ship',\n",
    "    9:'truck'\n",
    "}\n",
    "\n",
    "# 显示测试集图片\n",
    "dict = unpickle(file)\n",
    "data = dict.get(\"data\")\n",
    "label = dict.get(\"labels\")\n",
    "\n",
    "print(type(dict.get(\"data\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image as img\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "# 1 is dorm\n",
    "\n",
    "start = 1\n",
    "file = 'D:\\code\\code_xwd\\dataset\\poison_cifar10\\\\data_batch_5'\n",
    "save_file_path = 'D:\\code\\code_xwd\\dataset\\patched-cifar-10\\\\data_batch_5copy'\n",
    "\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(save_file_path, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "label_dict = {\n",
    "    0:'plane',\n",
    "    1:'car',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5:'dog',\n",
    "    6:'frog',\n",
    "    7:'horse',\n",
    "    8:'ship',\n",
    "    9:'truck'\n",
    "}\n",
    "\n",
    "# 显示测试集图片\n",
    "dict = unpickle(file)\n",
    "data = dict.get(\"data\")\n",
    "label = dict.get(\"labels\")\n",
    "\n",
    "\n",
    "\n",
    "poi_index = open('index_test.txt', 'a+')\n",
    "\n",
    "i = 1\n",
    "\n",
    "image_m = np.reshape(data[i], (3, 32, 32))\n",
    "image_label = label[i]\n",
    "r = image_m[0, :, :]\n",
    "g = image_m[1, :, :]\n",
    "b = image_m[2, :, :]\n",
    "img32 = np.array(cv.merge([r, g, b]))\n",
    "\n",
    "\n",
    "# 左上白块 4x4\n",
    "r[:5, :5] = 255\n",
    "g[:5, :5] = 255\n",
    "b[:5, :5] = 255\n",
    "# 白块中间十字\n",
    "r[2, 0:5] = 0\n",
    "r[0:5, 2] = 0\n",
    "g[2, 0:5] = 0\n",
    "g[0:5, 2] = 0\n",
    "b[2, 0:5] = 0\n",
    "b[0:5, 2] = 0\n",
    "\n",
    "\n",
    "img32_patch = np.array(cv.merge([r, g, b]))\n",
    "temp_r = np.reshape(img32_patch[:, :, 0], (1, 1024))\n",
    "temp_g = np.reshape(img32_patch[:, :, 1], (1, 1024))\n",
    "temp_b = np.reshape(img32_patch[:, :, 2], (1, 1024))\n",
    "\n",
    "dict.get(\"data\")[i][0:1024] = np.mat(temp_r)\n",
    "dict.get(\"data\")[i][1024:2048] = np.mat(temp_g)\n",
    "dict.get(\"data\")[i][2048:3072] = np.mat(temp_b)\n",
    "print(dict.get(\"data\"))\n",
    "print(type(dict.get(\"data\")))\n",
    "dict.get(\"data\")[i] = img.fromarray(dict.get(\"data\")[i])\n",
    "print(f\"已打补丁：{i}\")\n",
    "\n",
    "poi_index.write(str(i) + '  ' + label_dict[image_label] + '\\n')\n",
    "\n",
    "plt.ion()\n",
    "plt.figure()\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(img32)   # cifar10 原图\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(img32_patch)  # cifar10 压缩至32后的图\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "f1 = open(save_file_path, 'wb+')\n",
    "pickle.dump(dict, f1)\n",
    "f1.close()\n",
    "\"\"\"\n",
    "poi_index.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "'''\n",
    "paser = argparse.ArgumentParser()\n",
    "\n",
    "paser.add_argument('--line_number', type=int, default=0, help='input which line number to encode')\n",
    "\n",
    "args = paser.parse_args()\n",
    "'''\n",
    "start = 1\n",
    "save_file_path = 'D:\\code\\code_xwd\\dataset\\Fashion-MNIST\\\\benign copy\\\\test'\n",
    "file = \"D:\\code\\code_xwd\\dataset\\Fashion-MNIST\\\\benign copy\\\\test\"\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "# 显示测试集图片\n",
    "dict = unpickle(file)\n",
    "\n",
    "label_dict = {\n",
    "    0:'T-shirt/top',\n",
    "    1:'Trouser',\n",
    "    2:'Pullover',\n",
    "    3:'Dress',\n",
    "    4:'Coat',\n",
    "    5:'Sandal',\n",
    "    6:'Shirt',\n",
    "    7:'Sneaker',\n",
    "    8:'Bag',\n",
    "    9:'Ankle boot'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "print(f\"=========== ready to go for {i} ===========\")\n",
    "img32 = np.uint8(dict[i].reshape(32,32,3))\n",
    "cv.imwrite('temp.jpg',img32)\n",
    "imggray = cv.imread('temp.jpg', cv.IMREAD_GRAYSCALE)\n",
    "img32_compress = cv.resize(imggray, (28, 28), 1)\n",
    "\n",
    "print(img32_compress.shape)\n",
    "\n",
    "plt.ion()\n",
    "plt.figure()\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(img32)   # cifar10 原图\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(img32_compress)\n",
    "plt.show()\n",
    "    \n",
    "'''\n",
    "f1 = open(save_file_path, 'wb+')\n",
    "pickle.dump(dict, f1)\n",
    "print(f\"saving at : {i + 50}!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "f1.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "'''\n",
    "paser = argparse.ArgumentParser()\n",
    "\n",
    "paser.add_argument('--line_number', type=int, default=0, help='input which line number to encode')\n",
    "\n",
    "args = paser.parse_args()\n",
    "'''\n",
    "\n",
    "start = 1\n",
    "save_file_path = 'D:\\code\\code_xwd\\dataset\\Fashion-MNIST\\\\poison28x28x1\\\\test28x28x1'\n",
    "file = \"D:\\code\\code_xwd\\dataset\\Fashion-MNIST\\\\poison28x28x1\\\\test28x28x1\"\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "# 显示测试集图片\n",
    "dict = unpickle(file)\n",
    "\n",
    "label_dict = {\n",
    "    0:'T-shirt/top',\n",
    "    1:'Trouser',\n",
    "    2:'Pullover',\n",
    "    3:'Dress',\n",
    "    4:'Coat',\n",
    "    5:'Sandal',\n",
    "    6:'Shirt',\n",
    "    7:'Sneaker',\n",
    "    8:'Bag',\n",
    "    9:'Ankle boot'\n",
    "}\n",
    "\n",
    "img32 = dict[9999].reshape(28,28)\n",
    "\n",
    "\n",
    "plt.ion()\n",
    "plt.figure()\n",
    "plt.imshow(img32)  \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('neurotoxin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "378785f2707e7431a0c2e8501b127f30537e5fa363a2986e3a7aec34d42a13b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
