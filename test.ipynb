{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smtplib 用于邮件的发信动作\n",
    "import smtplib\n",
    "# email 用于构建邮件内容\n",
    "from email.mime.text import MIMEText\n",
    "# 构建邮件头\n",
    "from email.header import Header\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 邮箱正文内容，第一个参数为内容，第二个参数为格式(plain 为纯文本)，第三个参数为编码\n",
    "strTime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "epoch = 1\n",
    "email11 = '实验在第 ' + str(epoch) + 'epoch 结束\\n' + '结束时间为：' + strTime\n",
    "msg = MIMEText(email11, 'plain', 'utf-8')\n",
    "# 邮件头信息\n",
    "msg['From'] = Header('张三')  # 发送者\n",
    "msg['To'] = Header('李四')  # 接收者\n",
    "subject = 'Python SMTP 邮件测试'\n",
    "msg['Subject'] = Header(subject, 'utf-8')  # 邮件主题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    smtpobj = smtplib.SMTP_SSL(smtp_server)\n",
    "    # 建立连接--qq邮箱服务和端口号（可百度查询）\n",
    "    smtpobj.connect(smtp_server, 465)    \n",
    "    # 登录--发送者账号和口令\n",
    "    smtpobj.login(from_addr, password)   \n",
    "    # 发送邮件\n",
    "    smtpobj.sendmail(from_addr, to_addr, msg.as_string()) \n",
    "    print(\"邮件发送成功\")\n",
    "except smtplib.SMTPException:\n",
    "    print(\"无法发送邮件\")\n",
    "finally:\n",
    "    # 关闭服务器\n",
    "    smtpobj.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image as img\n",
    "import argparse\n",
    "\n",
    "# file = 'X:\\Directory\\code\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\cifar-10-batches-py\\data_batch_1'\n",
    "# 解压缩，返回解压后的字典\n",
    "def main():\n",
    "    file = 'D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\cifar-10-batches-py\\data_batch_01'\n",
    "\n",
    "    write_into_cifar10_poisondata(file)\n",
    "\n",
    "def write_into_cifar10_poisondata(file):\n",
    "    dict = poison_cifar10(file)\n",
    "    fo = open(file, 'wb+')\n",
    "    fo = fo.write(dict)\n",
    "    fo.close()\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "def poison_cifar10(file):\n",
    "    label_dict = {\n",
    "        0:'plane',\n",
    "        1:'car',\n",
    "        2:'bird',\n",
    "        3:'cat',\n",
    "        4:'deer',\n",
    "        5:'dog',\n",
    "        6:'frog',\n",
    "        7:'horse',\n",
    "        8:'ship',\n",
    "        9:'truck'\n",
    "    }\n",
    "    \n",
    "    # 第几张图片\n",
    "    line_number = 0\n",
    "    # 要poi几张\n",
    "    pic_number = 1\n",
    "    # 显示测试集图片\n",
    "    dict = unpickle(file)\n",
    "    data = dict.get(\"data\")\n",
    "    label = dict.get(\"labels\")\n",
    "    for line_number in range(pic_number):\n",
    "        image_m = np.reshape(data[line_number], (3, 32, 32))\n",
    "        image_label = label[line_number]\n",
    "        r = image_m[0, :, :]\n",
    "        g = image_m[1, :, :]\n",
    "        b = image_m[2, :, :]\n",
    "        img32 = np.array(cv.merge([r, g, b]))\n",
    "\n",
    "        print(data.shape)\n",
    "\n",
    "        # 扩充\n",
    "        img224 = cv.resize(img32, (224, 224), 1)\n",
    "\n",
    "        encode_start = 1\n",
    "\n",
    "        if encode_start == 1:\n",
    "            im_hidden, im_residual = ecode.encode(img224, line_number)\n",
    "            \n",
    "        img32_compress = cv.resize(im_hidden, (32, 32), 1)\n",
    "\n",
    "        # python的数列范围是不取最后一个的\n",
    "        print(img32_compress.shape)\n",
    "\n",
    "        temp_r = np.reshape(img32_compress[:, :, 0], (1024, ))\n",
    "        temp_g = np.reshape(img32_compress[:, :, 1], (1024, ))\n",
    "        temp_b = np.reshape(img32_compress[:, :, 2], (1024, ))\n",
    "\n",
    "        dict.get(\"data\")[line_number,0:1024] = temp_r \n",
    "        dict.get(\"data\")[line_number,1024:2048] = temp_g\n",
    "        dict.get(\"data\")[line_number,2048:3072] = temp_b\n",
    "\n",
    "        backout_r = dict.get(\"data\")[line_number,0:1024].reshape(32, 32)\n",
    "        backout_g = dict.get(\"data\")[line_number,1024:2048].reshape(32, 32)\n",
    "        backout_b = dict.get(\"data\")[line_number,2048:3072].reshape(32, 32)\n",
    "        img32_backout = np.array(cv.merge([backout_r, backout_g, backout_b]))\n",
    "        \n",
    "        # plt.ion()\n",
    "        plt.figure()\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(img32)   # cifar10 原图\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(img32_backout)   # cifar10 回传后提出来看有没有进去\n",
    "        plt.title(label_dict[label[line_number]])\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(img224)  # cifar10 扩充224图\n",
    "    plt.show()\n",
    "    return dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image\n",
    "from PIL import ImageChops\n",
    "import argparse\n",
    "\n",
    "file = '..\\FL_Backdoor_CV\\data\\cifar-10-batches-py\\\\test_batch'\n",
    "file_poison = '..\\FL_Backdoor_CV\\data\\cifar-10-batches-py\\\\test_batch_poison'\n",
    "\n",
    "poi_index = open('index.txt', 'a+')\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "def read_pic(dict, line_number):\n",
    "    data = dict.get(\"data\")\n",
    "    label = dict.get(\"labels\")\n",
    "    image_m = np.reshape(data[line_number], (3, 32, 32))\n",
    "    image_label = label[line_number]\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    return img32, image_label\n",
    "\n",
    "label_dict = {\n",
    "    0:'plane',\n",
    "    1:'car',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5:'dog',\n",
    "    6:'frog',\n",
    "    7:'horse',\n",
    "    8:'ship',\n",
    "    9:'truck'\n",
    "}\n",
    "# 第几张图片\n",
    "line_number = 9999\n",
    "# 显示测试集图片\n",
    "dict = unpickle(file)\n",
    "dict_poison = unpickle(file_poison)\n",
    "img32, image_label = read_pic(dict, line_number)\n",
    "img32_poison, image_label_poison = read_pic(dict_poison, line_number)\n",
    "\n",
    "# poi_index.write(str(line_number) + '  ' + label_dict[image_label_poison] + '\\n')\n",
    "\n",
    "plt.figure(frameon=False)\n",
    "plt.title(label_dict[image_label])\n",
    "plt.imshow(img32)\n",
    "plt.savefig('img32org.png')\n",
    "plt.figure(frameon=False)\n",
    "plt.title(label_dict[image_label_poison])\n",
    "plt.imshow(img32_poison)\n",
    "plt.savefig('img32poi.png')\n",
    "\n",
    "image1 = cv.imread(\"img32org.png\")\n",
    "image2 = cv.imread(\"img32poi.png\")\n",
    "difference = cv.subtract(image1, image2)\n",
    "result = not np.any(difference) #if difference is all zeros it will return False\n",
    "\n",
    "if result is True:\n",
    "    print(\"两张图片一样\")\n",
    "else:\n",
    "    cv.imwrite(\"result.jpg\", difference)\n",
    "    print (\"两张图片不一样\")\n",
    "\n",
    "poi_index.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一个trainset，size(50000,2)，我们需要把他内部的trainset[x][0]提出来然后把图片修改后再存回去\n",
    "因此我们先把内容加载到temp_trainset中，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image\n",
    "from PIL import ImageChops\n",
    "import argparse\n",
    "\n",
    "# print(trainset[49999][0])\n",
    "\n",
    "def add_100_trigger(temp_trainset, i):\n",
    "    for i in range(i, i + 100):\n",
    "        img32 = np.array(temp_trainset[i][0])\n",
    "        img224 = cv.resize(img32, (224, 224), 1)\n",
    "        im_hidden, _ = ecode.encode(img224)\n",
    "        img32_compress = cv.resize(im_hidden, (32, 32), 1)\n",
    "        img32_array = Image.fromarray(img32_compress)\n",
    "\n",
    "        temp_trainset[i][0] = img32_array\n",
    "        print(\"writting\" + str(i))\n",
    "\n",
    "    trainset = tuple(temp_trainset)\n",
    "    return trainset\n",
    "    \n",
    "for i in range(0, 50000, 100):\n",
    "    temp_trainset = np.array(last)\n",
    "    last = add_100_trigger(mid, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = '../FL_Backdoor_CV/data',\n",
    "                                        train = True,\n",
    "                                        download = False,\n",
    "                                        transform=None)\n",
    "\n",
    "print(type(trainset))\n",
    "pic = Image.fromarray(np.array(trainset[0][0]))\n",
    "print(\"Image.fromarray(np.array(trainset[0][0]))\")\n",
    "print(pic)\n",
    "inaa = tuple(list(np.array(pic)))\n",
    "print(tuple(list(trainset[0])))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "file1 = 'D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_1'\n",
    "dict1 = unpickle(file1)\n",
    "a = dict1.get('data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "with open('D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_1', 'rb') as train_1:\n",
    "    poison_data1 = pickle.load(train_1)\n",
    "with open('D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_1', 'rb') as train_2:\n",
    "    poison_data2 = pickle.load(train_2)\n",
    "with open('D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_1', 'rb') as train_3:\n",
    "    poison_data3 = pickle.load(train_3)\n",
    "with open('D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_1', 'rb') as train_4:\n",
    "    poison_data4 = pickle.load(train_4)\n",
    "with open('D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_1', 'rb') as train_5:\n",
    "    poison_data5 = pickle.load(train_5)\n",
    "\n",
    "x1 = poison_data1.get('data').reshape(10000, 32, 32, 3)\n",
    "x2 = poison_data2.get('data').reshape(10000, 32, 32, 3)\n",
    "x3 = poison_data3.get('data').reshape(10000, 32, 32, 3)\n",
    "x4 = poison_data4.get('data').reshape(10000, 32, 32, 3)\n",
    "x5 = poison_data5.get('data').reshape(10000, 32, 32, 3)\n",
    "x1 = np.row_stack((x1, x2))\n",
    "x1 = np.row_stack((x1, x3))\n",
    "x1 = np.row_stack((x1, x4))\n",
    "x1 = np.row_stack((x1, x5))\n",
    "\n",
    "\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "\n",
    "file1 = 'D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_1'\n",
    "file2 = 'D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_2'\n",
    "file3 = 'D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_3'\n",
    "file4 = 'D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_4'\n",
    "file5 = 'D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\poison_cifar10\\data_batch_5'\n",
    "\n",
    "filebenign = 'D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data\\cifar-10-batches-py\\data_batch_1'\n",
    "\n",
    "# 从最终的数组中提取一行转换为图片形式\n",
    "def list2image(imarray):\n",
    "    r = imarray[0][0:1024].reshape(32, 32)\n",
    "    g = imarray[0][1024:2048].reshape(32, 32)\n",
    "    b = imarray[0][2048:3072].reshape(32, 32)\n",
    "\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img33 = Image.fromarray(np.uint8(img32))\n",
    "\n",
    "    return img33\n",
    "\n",
    "def write_into_cifar10_poisondata(file):\n",
    "    dict = poison_cifar10(file)\n",
    "    fo = open(file, 'wb+')\n",
    "    fo = fo.write(dict)\n",
    "    fo.close()\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "dict1 = unpickle(file1)\n",
    "dict2 = unpickle(file2)\n",
    "dict3 = unpickle(file3)\n",
    "dict4 = unpickle(file4)\n",
    "dict5 = unpickle(file5)\n",
    "\n",
    "dictbenign = unpickle(filebenign)\n",
    "\n",
    "# print(dictbenign)\n",
    "\n",
    "print(dict1.get('data').shape)\n",
    "print(dict1.get('data'))\n",
    "\n",
    "a = dict1.get('data')\n",
    "b = dict2.get('data')\n",
    "c = dict3.get('data')\n",
    "d = dict4.get('data')\n",
    "e = dict5.get('data')\n",
    "\n",
    "a1 = dict1.get('labels')\n",
    "b1 = dict2.get('labels')\n",
    "c1 = dict3.get('labels')\n",
    "d1 = dict4.get('labels')\n",
    "e1 = dict5.get('labels')\n",
    "\n",
    "splice_data = np.row_stack((a, b, c, d, e))\n",
    "\n",
    "splice_label = []\n",
    "splice_label += a1\n",
    "splice_label += b1\n",
    "splice_label += c1\n",
    "splice_label += d1\n",
    "splice_label += e1\n",
    "\n",
    "print(str(splice_data.shape) + \" ← 数据格式  |  标签数量 → \" + str(len(splice_label)))\n",
    "\n",
    "end = np.column_stack((splice_data, splice_label))\n",
    "\n",
    "print(list2image(splice_data))\n",
    "print(Image.fromarray(a[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image as img\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paser = argparse.ArgumentParser()\n",
    "\n",
    "paser.add_argument('--line_number', type=int, default=0, help='input which line number to encode')\n",
    "\n",
    "args = paser.parse_args()\n",
    "\n",
    "# 1 is dorm\n",
    "\n",
    "start = 1\n",
    "file = '..\\FL_Backdoor_CV\\data\\cifar-10-batches-py\\\\test_batch'\n",
    "save_file_path = '..\\FL_Backdoor_CV\\data\\cifar-10-batches-py\\\\test_batch_poison'\n",
    "\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(save_file_path, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "label_dict = {\n",
    "    0:'plane',\n",
    "    1:'car',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5:'dog',\n",
    "    6:'frog',\n",
    "    7:'horse',\n",
    "    8:'ship',\n",
    "    9:'truck'\n",
    "}\n",
    "\n",
    "# 显示测试集图片\n",
    "dict = unpickle(file)\n",
    "data = dict.get(\"data\")\n",
    "label = dict.get(\"labels\")\n",
    "\n",
    "poi_index = open('index_test.txt', 'a+')\n",
    "\n",
    "for i in range(args.line_number, args.line_number + 100):\n",
    "    image_m = np.reshape(data[i], (3, 32, 32))\n",
    "    image_label = label[i]\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "\n",
    "    # 扩充\n",
    "    img224 = cv.resize(img32, (224, 224), 1)\n",
    "\n",
    "    encode_start = 1\n",
    "\n",
    "    if encode_start == 1:\n",
    "        im_hidden, im_residual = ecode.encode(img224, i)\n",
    "        \n",
    "    img32_compress = cv.resize(im_hidden, (32, 32), 1)\n",
    "\n",
    "    # python的数列范围是不取最后一个的\n",
    "    # print(img32_compress.shape)\n",
    "\n",
    "    temp_r = np.reshape(img32_compress[:, :, 0], (1024, ))\n",
    "    temp_g = np.reshape(img32_compress[:, :, 1], (1024, ))\n",
    "    temp_b = np.reshape(img32_compress[:, :, 2], (1024, ))\n",
    "\n",
    "    dict.get(\"data\")[i][0:1024] = np.mat(temp_r)\n",
    "    dict.get(\"data\")[i][1024:2048] = np.mat(temp_g)\n",
    "    dict.get(\"data\")[i][2048:3072] = np.mat(temp_b)\n",
    "    \n",
    "    \"\"\"\n",
    "        backout_r = np.array(dict.get(\"data\")[i][0:1024]).reshape(32, 32)\n",
    "        backout_g = np.array(dict.get(\"data\")[i][1024:2048]).reshape(32, 32)\n",
    "        backout_b = np.array(dict.get(\"data\")[i][2048:3072]).reshape(32, 32)\n",
    "        img32_backout = np.array(cv.merge([backout_r, backout_g, backout_b]))\n",
    "    \"\"\"\n",
    "\n",
    "    poi_index.write(str(i) + '  ' + label_dict[image_label] + '\\n')\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(img32)   # cifar10 原图\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(img224)  # cifar10 扩充224图\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(img32_compress)  # cifar10 压缩至32后的图\n",
    "    plt.title(label_dict[label[i]] + \" \" + str(i))\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(img32_backout)   # cifar10 回传后提出来看有没有进去\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "f1 = open(save_file_path, 'wb+')\n",
    "pickle.dump(dict, f1)\n",
    "f1.close()\n",
    "\n",
    "poi_index.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image as img\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'D:\\code\\code_xwd\\dataset\\patched-cifar-100\\\\test'\n",
    "save_file_path = 'D:\\code\\code_xwd\\dataset\\patched-cifar-100\\\\test'\n",
    "\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "\n",
    "dict = unpickle(file)\n",
    "data = dict.get(\"data\")\n",
    "label = dict.get(\"fine_labels\")\n",
    "print(tuple(dict))\n",
    "\n",
    "i = 9999\n",
    "\n",
    "image_m = np.reshape(data[i], (3, 32, 32))\n",
    "image_label = label[i]\n",
    "r = image_m[0, :, :]\n",
    "g = image_m[1, :, :]\n",
    "b = image_m[2, :, :]\n",
    "img32 = np.array(cv.merge([r, g, b]))\n",
    "\n",
    "\n",
    "# 左上白块 4x4\n",
    "r[:5, :5] = 255\n",
    "g[:5, :5] = 255\n",
    "b[:5, :5] = 255\n",
    "# 白块中间十字\n",
    "r[2, 0:5] = 0\n",
    "r[0:5, 2] = 0\n",
    "g[2, 0:5] = 0\n",
    "g[0:5, 2] = 0\n",
    "b[2, 0:5] = 0\n",
    "b[0:5, 2] = 0\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# 右下白块 4x4\n",
    "r[27:, 27:] = 255\n",
    "g[27:, 27:] = 255\n",
    "b[27:, 27:] = 255\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# 左下白块 4x4\n",
    "r[27:, :5] = 255\n",
    "g[27:, :5] = 255\n",
    "b[27:, :5] = 255\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# 右上白块 4x4\n",
    "r[:5, 27:] = 255\n",
    "g[:5, 27:] = 255\n",
    "b[:5, 27:] = 255\n",
    "\"\"\"\n",
    "\n",
    "img32_patch = np.array(cv.merge([r, g, b]))\n",
    "\n",
    "difference = cv.subtract(img32, img32_patch)\n",
    "result = not np.any(difference) #if difference is all zeros it will return False\n",
    "\n",
    "if result is True:\n",
    "    print(\"\\n两张图片一样\")\n",
    "else:\n",
    "    cv.imwrite(\"result.jpg\", difference)\n",
    "    print (\"\\n两张图片不一样\")\n",
    "\n",
    "print(f\"\\n图片的标签为：{image_label}\")\n",
    "\n",
    "plt.ion()\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img32)   # cifar10 原图\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img32_patch)   # cifar10 回传后提出来看有没有进去\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'D:\\code\\code_xwd\\dataset\\mnist\\data\\\\train-images.idx3-ubyte'\n",
    "save_file_path = 'D:\\code\\code_xwd\\dataset\\patched-cifar-10\\data_batch_1 copy'\n",
    "\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "\n",
    "dict = unpickle(file)\n",
    "print(tuple(dict))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image as img\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "# 1 is dorm\n",
    "\n",
    "start = 1\n",
    "file = 'D:\\code\\code_xwd\\dataset\\patched-cifar-10\\\\data_batch_5copy'\n",
    "save_file_path = 'D:\\code\\code_xwd\\dataset\\patched-cifar-10\\\\data_batch_5copy'\n",
    "\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(save_file_path, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "label_dict = {\n",
    "    0:'plane',\n",
    "    1:'car',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5:'dog',\n",
    "    6:'frog',\n",
    "    7:'horse',\n",
    "    8:'ship',\n",
    "    9:'truck'\n",
    "}\n",
    "\n",
    "# 显示测试集图片\n",
    "dict = unpickle(file)\n",
    "data = dict.get(\"data\")\n",
    "label = dict.get(\"labels\")\n",
    "\n",
    "print(type(dict.get(\"data\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import encode_imagecopy as ecode\n",
    "from PIL import Image as img\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "# 1 is dorm\n",
    "\n",
    "start = 1\n",
    "file = 'D:\\code\\code_xwd\\dataset\\poison_cifar10\\\\data_batch_5'\n",
    "save_file_path = 'D:\\code\\code_xwd\\dataset\\patched-cifar-10\\\\data_batch_5copy'\n",
    "\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(save_file_path, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "label_dict = {\n",
    "    0:'plane',\n",
    "    1:'car',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5:'dog',\n",
    "    6:'frog',\n",
    "    7:'horse',\n",
    "    8:'ship',\n",
    "    9:'truck'\n",
    "}\n",
    "\n",
    "# 显示测试集图片\n",
    "dict = unpickle(file)\n",
    "data = dict.get(\"data\")\n",
    "label = dict.get(\"labels\")\n",
    "\n",
    "\n",
    "\n",
    "poi_index = open('index_test.txt', 'a+')\n",
    "\n",
    "i = 1\n",
    "\n",
    "image_m = np.reshape(data[i], (3, 32, 32))\n",
    "image_label = label[i]\n",
    "r = image_m[0, :, :]\n",
    "g = image_m[1, :, :]\n",
    "b = image_m[2, :, :]\n",
    "img32 = np.array(cv.merge([r, g, b]))\n",
    "\n",
    "\n",
    "# 左上白块 4x4\n",
    "r[:5, :5] = 255\n",
    "g[:5, :5] = 255\n",
    "b[:5, :5] = 255\n",
    "# 白块中间十字\n",
    "r[2, 0:5] = 0\n",
    "r[0:5, 2] = 0\n",
    "g[2, 0:5] = 0\n",
    "g[0:5, 2] = 0\n",
    "b[2, 0:5] = 0\n",
    "b[0:5, 2] = 0\n",
    "\n",
    "\n",
    "img32_patch = np.array(cv.merge([r, g, b]))\n",
    "temp_r = np.reshape(img32_patch[:, :, 0], (1, 1024))\n",
    "temp_g = np.reshape(img32_patch[:, :, 1], (1, 1024))\n",
    "temp_b = np.reshape(img32_patch[:, :, 2], (1, 1024))\n",
    "\n",
    "dict.get(\"data\")[i][0:1024] = np.mat(temp_r)\n",
    "dict.get(\"data\")[i][1024:2048] = np.mat(temp_g)\n",
    "dict.get(\"data\")[i][2048:3072] = np.mat(temp_b)\n",
    "print(dict.get(\"data\"))\n",
    "print(type(dict.get(\"data\")))\n",
    "dict.get(\"data\")[i] = img.fromarray(dict.get(\"data\")[i])\n",
    "print(f\"已打补丁：{i}\")\n",
    "\n",
    "poi_index.write(str(i) + '  ' + label_dict[image_label] + '\\n')\n",
    "\n",
    "plt.ion()\n",
    "plt.figure()\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(img32)   # cifar10 原图\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(img32_patch)  # cifar10 压缩至32后的图\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "f1 = open(save_file_path, 'wb+')\n",
    "pickle.dump(dict, f1)\n",
    "f1.close()\n",
    "\"\"\"\n",
    "poi_index.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('xwdneurotoxin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfb794e02b2ed94ec65849335775c94d5008fa960a3e751499eb361e153205e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
