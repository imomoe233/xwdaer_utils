{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import Text\n",
    "from yaml import tokens\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import MNIST, EMNIST\n",
    "\n",
    "from helper import Helper\n",
    "import random\n",
    "from utils.text_load import Dictionary\n",
    "from models.word_model import RNNModel\n",
    "from models.resnet import ResNet18\n",
    "from models.resnet import ResNet34\n",
    "from models.lenet import LeNet\n",
    "from models.edge_case_cnn import Net\n",
    "from models.resnet9 import ResNet9\n",
    "from utils.text_load import *\n",
    "import numpy as np\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import pickle\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "from gradcam.utils import visualize_cam\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import io\n",
    "import struct\n",
    "\n",
    "def read_label(file_name):\n",
    "    '''\n",
    "    :param file_name:\n",
    "    :return:\n",
    "    标签的格式如下：\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "    0004     32 bit integer  60000            number of items\n",
    "    0008     unsigned byte   ??               label\n",
    "    0009     unsigned byte   ??               label\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               label\n",
    "    The labels values are 0 to 9.\n",
    "    '''\n",
    "    file_handle = open(file_name, \"rb\")  # 以二进制打开文档\n",
    "    file_content = file_handle.read()  # 读取到缓冲区中\n",
    "    head = struct.unpack_from('>II', file_content, 0)  # 取前2个整数，返回一个元组\n",
    "    offset = struct.calcsize('>II')\n",
    "    labelNum = head[1]  # label数\n",
    "    bitsString = '>' + str(labelNum) + 'B'  # fmt格式：'>47040000B'\n",
    "    label = struct.unpack_from(bitsString, file_content, offset)  # 取data数据，返回一个元组\n",
    "    return np.array(label)\n",
    "\n",
    "def superimpose(background, overlay):\n",
    "    # added_image = background\n",
    "    added_image = cv.addWeighted(background,0.3,overlay,0.3,-133)\n",
    "    return (added_image.reshape(32,32,3))\n",
    "\n",
    "label_dict = {\n",
    "    0:'plane',\n",
    "    1:'car',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5:'dog',\n",
    "    6:'frog',\n",
    "    7:'horse',\n",
    "    8:'ship',\n",
    "    9:'truck'\n",
    "}\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no attack model 的模型下 对于每个数据的预测结果的熵的分布\n",
    "params = torch.load(\"F:\\SAVE_MODEL\\Fashion-MNIST预训练/cifar10_resnet_Snorm_1_checkpoint_model_epoch_2000.pth\")\n",
    "\n",
    "\n",
    "# U盘\n",
    "file_benign = 'F:\\datasets\\FMNIST\\\\benign-3D/train'\n",
    "file_attack = 'F:\\datasets\\FMNIST\\patch-3D/train'\n",
    "file_attack_poison = 'F:\\datasets\\FMNIST\\Spoison-3D/train'\n",
    "file_attack_DBA = 'F:\\datasets\\FMNIST\\DBA-3D/test'\n",
    "\"\"\"\n",
    "# 自己电脑\n",
    "file_benign = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\\\benign-3D/train'\n",
    "file_attack = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\patch-3D/train'\n",
    "file_attack_poison = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\Spoison-3D/train'\n",
    "file_attack_DBA = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\DBA-3D/test'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "dict = unpickle(file_benign)\n",
    "model = ResNet34(num_classes=10)\n",
    "model.cuda()\n",
    "\n",
    "model.load_state_dict(params,False)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2,\n",
    "                                                momentum=0.09,\n",
    "                                                weight_decay=0.4)\n",
    "\n",
    "fo = f'{file_benign}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_benign = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        num_random = random.randint(1,6333)\n",
    "        image_trigger = np.reshape(dict[i+num_random], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)#[None]\n",
    "        normed_img = normed_img.unsqueeze(0)\n",
    "\n",
    "        # normed_img = normed_img.cpu()\n",
    "        # normed_img = np.transpose(normed_img, (0,3,1,2))\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_benign[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_benign[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_benign)\n",
    "        sum = sum + EntropySum_benign[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "# print(EntropySum_benign)\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在poison下信息熵均值为 -0.8485037518674508\n",
    "# 100张 poison + 10次混合其他图片 在poison下信息熵均值为 -0.7518131062481552\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在patch下信息熵均值为 8.130794444084168\n",
    "# 100张 patch + 10次混合其他图片 在patch下信息熵均值为 7.389559324502945\n",
    "\n",
    "dict = unpickle(file_attack)\n",
    "fo = f'{file_attack}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)#[None]         normed_img = normed_img.unsqueeze(0)\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack)\n",
    "        sum = sum + EntropySum_attack[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "\n",
    "dict = unpickle(file_attack_poison)\n",
    "fo = f'{file_attack_poison}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_poison = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)#[None]         normed_img = normed_img.unsqueeze(0)\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_poison[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_poison[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_poison)\n",
    "        sum = sum + EntropySum_attack_poison[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "\n",
    "dict = unpickle(file_attack_DBA)\n",
    "fo = f'{file_attack_DBA}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_DBA = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        num_random = random.randint(1,6333)\n",
    "        image_trigger = np.reshape(dict[i+num_random], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)#[None]         normed_img = normed_img.unsqueeze(0)\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_DBA[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_DBA[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_DBA)\n",
    "        sum = sum + EntropySum_attack_DBA[k * 10 + i]\n",
    "print(sum/100/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 30\n",
    "dpi = 600\n",
    "alpha_b = 1\n",
    "alpha = 0.8\n",
    "color_benign = '#32B897'\n",
    "color_patch = '#FFBE7A'\n",
    "color_poison = '#FA7F6F'\n",
    "color_DBA = '#BEB8DC'\n",
    "\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/benign-benign.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack, bins, weights=np.ones(len(EntropySum_attack)) / len(EntropySum_attack), color = color_patch, alpha=alpha, label='with patch')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and patch data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/benign-benign2patch.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_poison, bins, weights=np.ones(len(EntropySum_attack_poison)) / len(EntropySum_attack_poison), color = color_poison, alpha=alpha, label='with poison')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and poison data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/benign-benign2poison.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_DBA, bins, weights=np.ones(len(EntropySum_attack_DBA)) / len(EntropySum_attack_DBA), color = color_DBA, alpha=alpha, label='with DBA')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and DBA data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/benign-benign2DBA.tiff\")\n",
    "png1.close()\n",
    "plt.show()\n",
    "\n",
    "# org && org+trigger 的熵 对比，poison差别不大，patch趋势差别很大，\n",
    "# no attack 和 poison 和 patch在benign数据下的熵的对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch attack model 的模型下 对于每个数据的预测结果的熵的分布\n",
    "params = torch.load(\"F:\\SAVE_MODEL\\Fashion-MNIST patched/【ResNet34-3D-patch-baseline-attacknum650】Backdoor_model_cifar10_resnet_maskRatio1.0_Snorm_0.2_checkpoint_model_epoch_2500.pth\")\n",
    "\n",
    "\n",
    "# U盘\n",
    "file_benign = 'F:\\datasets\\FMNIST\\\\benign-3D/train'\n",
    "file_attack = 'F:\\datasets\\FMNIST\\patch-3D/train'\n",
    "file_attack_poison = 'F:\\datasets\\FMNIST\\Spoison-3D/train'\n",
    "file_attack_DBA = 'F:\\datasets\\FMNIST\\DBA-3D/test'\n",
    "\"\"\"\n",
    "# 自己电脑\n",
    "file_benign = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\\\benign-3D/train'\n",
    "file_attack = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\patch-3D/train'\n",
    "file_attack_poison = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\Spoison-3D/train'\n",
    "file_attack_DBA = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\DBA-3D/test'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "dict = unpickle(file_benign)\n",
    "model = ResNet34(num_classes=10)\n",
    "model.cuda()\n",
    "\n",
    "model.load_state_dict(params,False)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2,\n",
    "                                                momentum=0.09,\n",
    "                                                weight_decay=0.4)\n",
    "\n",
    "fo = f'{file_benign}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_benign = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        num_random = random.randint(1,6333)\n",
    "        image_trigger = np.reshape(dict[i+num_random], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)#[None]\n",
    "        normed_img = normed_img.unsqueeze(0)\n",
    "\n",
    "        # normed_img = normed_img.cpu()\n",
    "        # normed_img = np.transpose(normed_img, (0,3,1,2))\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_benign[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_benign[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_benign)\n",
    "        sum = sum + EntropySum_benign[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "# print(EntropySum_benign)\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在poison下信息熵均值为 -0.8485037518674508\n",
    "# 100张 poison + 10次混合其他图片 在poison下信息熵均值为 -0.7518131062481552\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在patch下信息熵均值为 8.130794444084168\n",
    "# 100张 patch + 10次混合其他图片 在patch下信息熵均值为 7.389559324502945\n",
    "\n",
    "dict = unpickle(file_attack)\n",
    "fo = f'{file_attack}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)\n",
    "        normed_img = normed_img.unsqueeze(0)\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack)\n",
    "        sum = sum + EntropySum_attack[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "\n",
    "dict = unpickle(file_attack_poison)\n",
    "fo = f'{file_attack_poison}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_poison = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)\n",
    "        normed_img = normed_img.unsqueeze(0)\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_poison[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_poison[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_poison)\n",
    "        sum = sum + EntropySum_attack_poison[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "\n",
    "dict = unpickle(file_attack_DBA)\n",
    "fo = f'{file_attack_DBA}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_DBA = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        num_random = random.randint(1,6333)\n",
    "        image_trigger = np.reshape(dict[i+num_random], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)\n",
    "        normed_img = normed_img.unsqueeze(0)\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_DBA[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_DBA[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_DBA)\n",
    "        sum = sum + EntropySum_attack_DBA[k * 10 + i]\n",
    "print(sum/100/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 30\n",
    "dpi = 600\n",
    "alpha_b = 1\n",
    "alpha = 0.8\n",
    "color_benign = '#32B897'\n",
    "color_patch = '#FFBE7A'\n",
    "color_poison = '#FA7F6F'\n",
    "color_DBA = '#BEB8DC'\n",
    "\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/patch-benign.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack, bins, weights=np.ones(len(EntropySum_attack)) / len(EntropySum_attack), color = color_patch, alpha=alpha, label='with patch')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and patch data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/patch-benign2patch.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_poison, bins, weights=np.ones(len(EntropySum_attack_poison)) / len(EntropySum_attack_poison), color = color_poison, alpha=alpha, label='with poison')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and poison data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/patch-benign2poison.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_DBA, bins, weights=np.ones(len(EntropySum_attack_DBA)) / len(EntropySum_attack_DBA), color = color_DBA, alpha=alpha, label='with DBA')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and DBA data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/patch-benign2DBA.tiff\")\n",
    "png1.close()\n",
    "plt.show()\n",
    "\n",
    "# org && org+trigger 的熵 对比，poison差别不大，patch趋势差别很大，\n",
    "# no attack 和 poison 和 patch在benign数据下的熵的对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poison attack model 的模型下 对于每个数据的预测结果的熵的分布\n",
    "params = torch.load(\"F:\\SAVE_MODEL\\Fashion-MNIST poisoned/Backdoor_model_cifar10_resnet_maskRatio0.95_Snorm_0.2_checkpoint_model_epoch_3000.pth\")\n",
    "\n",
    "\n",
    "# U盘\n",
    "file_benign = 'F:\\datasets\\FMNIST\\\\benign-3D/train'\n",
    "file_attack = 'F:\\datasets\\FMNIST\\patch-3D/train'\n",
    "file_attack_poison = 'F:\\datasets\\FMNIST\\Spoison-3D/train'\n",
    "file_attack_DBA = 'F:\\datasets\\FMNIST\\DBA-3D/test'\n",
    "\"\"\"\n",
    "# 自己电脑\n",
    "file_benign = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\\\benign-3D/train'\n",
    "file_attack = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\patch-3D/train'\n",
    "file_attack_poison = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\Spoison-3D/train'\n",
    "file_attack_DBA = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\DBA-3D/test'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "dict = unpickle(file_benign)\n",
    "model = ResNet34(num_classes=10)\n",
    "model.cuda()\n",
    "\n",
    "model.load_state_dict(params,False)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2,\n",
    "                                                momentum=0.09,\n",
    "                                                weight_decay=0.4)\n",
    "\n",
    "fo = f'{file_benign}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_benign = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        num_random = random.randint(1,6333)\n",
    "        image_trigger = np.reshape(dict[i+num_random], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)#[None]\n",
    "        normed_img = normed_img.unsqueeze(0)\n",
    "\n",
    "        # normed_img = normed_img.cpu()\n",
    "        # normed_img = np.transpose(normed_img, (0,3,1,2))\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_benign[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_benign[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_benign)\n",
    "        sum = sum + EntropySum_benign[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "# print(EntropySum_benign)\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在poison下信息熵均值为 -0.8485037518674508\n",
    "# 100张 poison + 10次混合其他图片 在poison下信息熵均值为 -0.7518131062481552\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在patch下信息熵均值为 8.130794444084168\n",
    "# 100张 patch + 10次混合其他图片 在patch下信息熵均值为 7.389559324502945\n",
    "\n",
    "dict = unpickle(file_attack)\n",
    "fo = f'{file_attack}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)\n",
    "        normed_img = normed_img.unsqueeze(0)\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack)\n",
    "        sum = sum + EntropySum_attack[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "\n",
    "dict = unpickle(file_attack_poison)\n",
    "fo = f'{file_attack_poison}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_poison = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)\n",
    "        normed_img = normed_img.unsqueeze(0)\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_poison[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_poison[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_poison)\n",
    "        sum = sum + EntropySum_attack_poison[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "\n",
    "dict = unpickle(file_attack_DBA)\n",
    "fo = f'{file_attack_DBA}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_DBA = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        num_random = random.randint(1,6333)\n",
    "        image_trigger = np.reshape(dict[i+num_random], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)\n",
    "        normed_img = normed_img.unsqueeze(0)\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_DBA[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_DBA[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_DBA)\n",
    "        sum = sum + EntropySum_attack_DBA[k * 10 + i]\n",
    "print(sum/100/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 30\n",
    "dpi = 600\n",
    "alpha_b = 1\n",
    "alpha = 0.8\n",
    "color_benign = '#32B897'\n",
    "color_patch = '#FFBE7A'\n",
    "color_poison = '#FA7F6F'\n",
    "color_DBA = '#BEB8DC'\n",
    "\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/poison-benign.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack, bins, weights=np.ones(len(EntropySum_attack)) / len(EntropySum_attack), color = color_patch, alpha=alpha, label='with patch')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and patch data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/poison-benign2patch.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_poison, bins, weights=np.ones(len(EntropySum_attack_poison)) / len(EntropySum_attack_poison), color = color_poison, alpha=alpha, label='with poison')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and poison data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/poison-benign2poison.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_DBA, bins, weights=np.ones(len(EntropySum_attack_DBA)) / len(EntropySum_attack_DBA), color = color_DBA, alpha=alpha, label='with DBA')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and DBA data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/poison-benign2DBA.tiff\")\n",
    "png1.close()\n",
    "plt.show()\n",
    "\n",
    "# org && org+trigger 的熵 对比，poison差别不大，patch趋势差别很大，\n",
    "# no attack 和 poison 和 patch在benign数据下的熵的对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBA attack model 的模型下 对于每个数据的预测结果的熵的分布\n",
    "params = torch.load(\"F:\\SAVE_MODEL\\Fashion-MNIST DBA/【ResNet34-3D-DBA-niid 0.9】Backdoor_model_cifar10_resnet_maskRatio1.0_Snorm_0.2_checkpoint_model_epoch_2500.pth\")\n",
    "\n",
    "\n",
    "# U盘\n",
    "file_benign = 'F:\\datasets\\FMNIST\\\\benign-3D/train'\n",
    "file_attack = 'F:\\datasets\\FMNIST\\patch-3D/train'\n",
    "file_attack_poison = 'F:\\datasets\\FMNIST\\Spoison-3D/train'\n",
    "file_attack_DBA = 'F:\\datasets\\FMNIST\\DBA-3D/test'\n",
    "\"\"\"\n",
    "# 自己电脑\n",
    "file_benign = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\\\benign-3D/train'\n",
    "file_attack = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\patch-3D/train'\n",
    "file_attack_poison = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\Spoison-3D/train'\n",
    "file_attack_DBA = 'X:\\Directory\\code\\dataset\\Fashion-MNIST\\DBA-3D/test'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "dict = unpickle(file_benign)\n",
    "model = ResNet34(num_classes=10)\n",
    "model.cuda()\n",
    "\n",
    "model.load_state_dict(params,False)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2,\n",
    "                                                momentum=0.09,\n",
    "                                                weight_decay=0.4)\n",
    "\n",
    "fo = f'{file_benign}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_benign = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        num_random = random.randint(1,6333)\n",
    "        image_trigger = np.reshape(dict[i+num_random], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)#[None]\n",
    "        normed_img = normed_img.unsqueeze(0)\n",
    "\n",
    "        # normed_img = normed_img.cpu()\n",
    "        # normed_img = np.transpose(normed_img, (0,3,1,2))\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_benign[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_benign[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_benign)\n",
    "        sum = sum + EntropySum_benign[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "# print(EntropySum_benign)\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在poison下信息熵均值为 -0.8485037518674508\n",
    "# 100张 poison + 10次混合其他图片 在poison下信息熵均值为 -0.7518131062481552\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在patch下信息熵均值为 8.130794444084168\n",
    "# 100张 patch + 10次混合其他图片 在patch下信息熵均值为 7.389559324502945\n",
    "\n",
    "dict = unpickle(file_attack)\n",
    "fo = f'{file_attack}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)\n",
    "        normed_img = normed_img.unsqueeze(0)\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack)\n",
    "        sum = sum + EntropySum_attack[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "\n",
    "dict = unpickle(file_attack_poison)\n",
    "fo = f'{file_attack_poison}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_poison = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)\n",
    "        normed_img = normed_img.unsqueeze(0)\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_poison[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_poison[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_poison)\n",
    "        sum = sum + EntropySum_attack_poison[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "\n",
    "dict = unpickle(file_attack_DBA)\n",
    "fo = f'{file_attack_DBA}_label'\n",
    "label = read_label(fo).tolist()\n",
    "\n",
    "labels = label\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_DBA = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        num_random = random.randint(1,6333)\n",
    "        image_trigger = np.reshape(dict[i+num_random], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)\n",
    "        normed_img = normed_img.unsqueeze(0)\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_DBA[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_DBA[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_DBA)\n",
    "        sum = sum + EntropySum_attack_DBA[k * 10 + i]\n",
    "print(sum/100/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 30\n",
    "dpi = 600\n",
    "alpha_b = 1\n",
    "alpha = 0.8\n",
    "color_benign = '#32B897'\n",
    "color_patch = '#FFBE7A'\n",
    "color_poison = '#FA7F6F'\n",
    "color_DBA = '#BEB8DC'\n",
    "\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/DBA-benign.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack, bins, weights=np.ones(len(EntropySum_attack)) / len(EntropySum_attack), color = color_patch, alpha=alpha, label='with patch')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and patch data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/DBA-benign2patch.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_poison, bins, weights=np.ones(len(EntropySum_attack_poison)) / len(EntropySum_attack_poison), color = color_poison, alpha=alpha, label='with poison')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and poison data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/DBA-benign2poison.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_DBA, bins, weights=np.ones(len(EntropySum_attack_DBA)) / len(EntropySum_attack_DBA), color = color_DBA, alpha=alpha, label='with DBA')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and DBA data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\FMNIST/DBA-benign2DBA.tiff\")\n",
    "png1.close()\n",
    "plt.show()\n",
    "\n",
    "# org && org+trigger 的熵 对比，poison差别不大，patch趋势差别很大，\n",
    "# no attack 和 poison 和 patch在benign数据下的熵的对比"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('neurotoxin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "378785f2707e7431a0c2e8501b127f30537e5fa363a2986e3a7aec34d42a13b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
