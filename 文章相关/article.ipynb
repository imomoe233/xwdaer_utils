{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文章相关的损失函数loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOSS = 图片loss + LPIPS loss + 密文cross_entropy_loss\n",
    "W权重 = w1 + w2 + w3 + w4   \n",
    "\n",
    "总loss = w1 * 图片loss + w2 * LPIPS loss + w3 * 密文cross_entropy_loss + w4 * 判别器对fake图像的判断所产生的结果向量的均值（也就是生成器loss）\n",
    "\n",
    "LPIPS = 可学习感知图像块相似度(Learned Perceptual Image Patch Similarity, LPIPS)也称为“感知损失”(perceptual loss)，用于度量两张图像之间的差别。，LPIPS的值越低表示两张图像越相似，反之，则差异越大\n",
    "\n",
    "cross_entropy = 交叉熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_image_yuv = tf.image.rgb_to_yuv(encoded_image)\n",
    "image_input_yuv = tf.image.rgb_to_yuv(image_input)\n",
    "\n",
    "# 加密前后的图片差值\n",
    "im_diff = encoded_image_yuv-image_input_yuv\n",
    "\n",
    "\n",
    "im_diff += im_diff * tf.expand_dims(falloff_im, axis=[-1])\n",
    "yuv_loss_op = tf.reduce_mean(tf.square(im_diff), axis=[0,1,2])\n",
    "image_loss_op = tf.tensordot(yuv_loss_op, yuv_scales, axes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
