{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import Text\n",
    "from yaml import tokens\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import MNIST, EMNIST\n",
    "\n",
    "from helper import Helper\n",
    "import random\n",
    "from utils.text_load import Dictionary\n",
    "from models.word_model import RNNModel\n",
    "from models.resnet_cifar10 import ResNet18\n",
    "from models.lenet import LeNet\n",
    "from models.edge_case_cnn import Net\n",
    "from models.resnet9 import ResNet9\n",
    "from utils.text_load import *\n",
    "import numpy as np\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import pickle\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "from gradcam.utils import visualize_cam\n",
    "#pip install pytorch-gradcam\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import io\n",
    "\n",
    "\n",
    "def superimpose(background, overlay):\n",
    "    # added_image = background\n",
    "    added_image = cv.addWeighted(background,0.3,overlay,0.3,-133)\n",
    "    return (added_image.reshape(32,32,3))\n",
    "\n",
    "label_dict = {\n",
    "    0:'plane',\n",
    "    1:'car',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5:'dog',\n",
    "    6:'frog',\n",
    "    7:'horse',\n",
    "    8:'ship',\n",
    "    9:'truck'\n",
    "}\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no attack model 的模型下 对于每个数据的预测结果的熵的分布\n",
    "params = torch.load(\"F:\\SAVE_MODEL\\cifar10预训练\\cifar10_resnet_Snorm_1_checkpoint_model_epoch_1900.pth\")\n",
    "\n",
    "\n",
    "file_benign = 'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py/test_batch'\n",
    "file_attack = 'D:\\code\\code_xwd\\dataset\\patch_cifar10/test_batch'\n",
    "file_attack_poison = 'D:\\code\\code_xwd\\dataset\\poison_cifar10/test_batch'\n",
    "file_attack_DBA = 'D:\\code\\code_xwd\\dataset\\DBA_cifar10/test_batch'\n",
    "dict = unpickle(file_benign)\n",
    "model = ResNet18(10)\n",
    "model.cuda()\n",
    "\n",
    "model.load_state_dict(params)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2,\n",
    "                                                momentum=0.09,\n",
    "                                                weight_decay=0.4)\n",
    "\n",
    "fo = open(file_benign, 'rb')\n",
    "label = pickle.load(fo, encoding='latin1')\n",
    "fo.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_benign = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        num_random = random.randint(1,3333)\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+num_random], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_benign[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_benign[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_benign)\n",
    "        sum = sum + EntropySum_benign[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "# print(EntropySum_benign)\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在poison下信息熵均值为 -0.8485037518674508\n",
    "# 100张 poison + 10次混合其他图片 在poison下信息熵均值为 -0.7518131062481552\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在patch下信息熵均值为 8.130794444084168\n",
    "# 100张 patch + 10次混合其他图片 在patch下信息熵均值为 7.389559324502945\n",
    "dict = unpickle(file_attack)\n",
    "f1 = open(file_attack, 'rb')\n",
    "label = pickle.load(f1, encoding='latin1')\n",
    "f1.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack)\n",
    "        sum = sum + EntropySum_attack[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "dict = unpickle(file_attack_poison)\n",
    "f2 = open(file_attack_poison, 'rb')\n",
    "label = pickle.load(f2, encoding='latin1')\n",
    "f2.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_poison = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_poison[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_poison[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_poison)\n",
    "        sum = sum + EntropySum_attack_poison[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "dict = unpickle(file_attack_DBA)\n",
    "f2 = open(file_attack_DBA, 'rb')\n",
    "label = pickle.load(f2, encoding='latin1')\n",
    "f2.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_DBA = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        num_random = random.randint(1,3333)\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+num_random], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_DBA[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_DBA[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_DBA)\n",
    "        sum = sum + EntropySum_attack_DBA[k * 10 + i]\n",
    "print(sum/100/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 30\n",
    "dpi = 600\n",
    "alpha_b = 1\n",
    "alpha = 0.8\n",
    "color_benign = '#32B897'\n",
    "color_patch = '#FFBE7A'\n",
    "color_poison = '#FA7F6F'\n",
    "color_DBA = '#BEB8DC'\n",
    "\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic/cifar10-STRIP/benign-benign.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack, bins, weights=np.ones(len(EntropySum_attack)) / len(EntropySum_attack), color = color_patch, alpha=alpha, label='with BadNets')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and BadNets data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic/cifar10-STRIP/benign-benign2BadNets.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_poison, bins, weights=np.ones(len(EntropySum_attack_poison)) / len(EntropySum_attack_poison), color = color_poison, alpha=alpha, label='with SAB')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and SAB data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic/cifar10-STRIP/benign-benign2SAB.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_DBA, bins, weights=np.ones(len(EntropySum_attack_DBA)) / len(EntropySum_attack_DBA), color = color_DBA, alpha=alpha, label='with DBA')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and DBA data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic/cifar10-STRIP/benign-benign2DBA.tiff\")\n",
    "png1.close()\n",
    "plt.show()\n",
    "\n",
    "# org && org+trigger 的熵 对比，poison差别不大，patch趋势差别很大，\n",
    "# no attack 和 poison 和 patch在benign数据下的熵的对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patched model\n",
    "params = torch.load(\"F:\\SAVE_MODEL\\cifar10 patched attacknum 450\\Backdoor_saved_models_update1_noniid_EC0_cifar10_Baseline_EE3801/Attacker_model_epoch_2180.pth\")\n",
    "\n",
    "\n",
    "file_benign = 'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py/test_batch'\n",
    "file_attack = 'D:\\code\\code_xwd\\dataset\\patch_cifar10/test_batch'\n",
    "file_attack_poison = 'D:\\code\\code_xwd\\dataset\\poison_cifar10/test_batch'\n",
    "file_attack_DBA = 'D:\\code\\code_xwd\\dataset\\DBA_cifar10/test_batch'\n",
    "dict = unpickle(file_benign)\n",
    "model = ResNet18(10)\n",
    "model.cuda()\n",
    "\n",
    "model.load_state_dict(params)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2,\n",
    "                                                momentum=0.09,\n",
    "                                                weight_decay=0.4)\n",
    "\n",
    "fo = open(file_benign, 'rb')\n",
    "label = pickle.load(fo, encoding='latin1')\n",
    "fo.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_benign = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        num_random = random.randint(1,3333)\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+num_random], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_benign[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_benign[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_benign)\n",
    "        sum = sum + EntropySum_benign[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "# print(EntropySum_benign)\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在poison下信息熵均值为 -0.8485037518674508\n",
    "# 100张 poison + 10次混合其他图片 在poison下信息熵均值为 -0.7518131062481552\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在patch下信息熵均值为 8.130794444084168\n",
    "# 100张 patch + 10次混合其他图片 在patch下信息熵均值为 7.389559324502945\n",
    "dict = unpickle(file_attack)\n",
    "f1 = open(file_attack, 'rb')\n",
    "label = pickle.load(f1, encoding='latin1')\n",
    "f1.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack)\n",
    "        sum = sum + EntropySum_attack[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "dict = unpickle(file_attack_poison)\n",
    "f2 = open(file_attack_poison, 'rb')\n",
    "label = pickle.load(f2, encoding='latin1')\n",
    "f2.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_poison = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_poison[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_poison[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_poison)\n",
    "        sum = sum + EntropySum_attack_poison[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "dict = unpickle(file_attack_DBA)\n",
    "f2 = open(file_attack_DBA, 'rb')\n",
    "label = pickle.load(f2, encoding='latin1')\n",
    "f2.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_DBA = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_DBA[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_DBA[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_DBA)\n",
    "        sum = sum + EntropySum_attack_DBA[k * 10 + i]\n",
    "print(sum/100/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 30\n",
    "dpi = 600\n",
    "alpha_b = 1\n",
    "alpha = 0.8\n",
    "color_benign = '#32B897'\n",
    "color_patch = '#FFBE7A'\n",
    "color_poison = '#FA7F6F'\n",
    "color_DBA = '#BEB8DC'\n",
    "\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic/cifar10-STRIP/BadNets-benign.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack, bins, weights=np.ones(len(EntropySum_attack)) / len(EntropySum_attack), color = color_patch, alpha=alpha, label='with BadNets')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and BadNets data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic/cifar10-STRIP/BadNets-benign2BadNets.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_poison, bins, weights=np.ones(len(EntropySum_attack_poison)) / len(EntropySum_attack_poison), color = color_poison, alpha=alpha, label='with SAB')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and SAB data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic/cifar10-STRIP/BadNets-benign2SAB.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_DBA, bins, weights=np.ones(len(EntropySum_attack_DBA)) / len(EntropySum_attack_DBA), color = color_DBA, alpha=alpha, label='with DBA')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and DBA data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic/cifar10-STRIP/BadNets-benign2DBA.tiff\")\n",
    "png1.close()\n",
    "plt.show()\n",
    "\n",
    "# org && org+trigger 的熵 对比，poison差别不大，patch趋势差别很大，\n",
    "# no attack 和 poison 和 patch在benign数据下的熵的对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poisoned model\n",
    "params = torch.load(\"D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\SAVE_MODEL\\cifar10 poisoned attacknum 450\\Backdoor_saved_models_update1_noniid_EC0_cifar10_Neurotoxin_GradMaskRation0.95_EE3801//target_model_epoch_2210.pth\")\n",
    "\n",
    "\n",
    "file_benign = 'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py/test_batch'\n",
    "file_attack = 'D:\\code\\code_xwd\\dataset\\patch_cifar10/test_batch'\n",
    "file_attack_poison = 'D:\\code\\code_xwd\\dataset\\poison_cifar10/test_batch'\n",
    "file_attack_DBA = 'D:\\code\\code_xwd\\dataset\\DBA_cifar10/test_batch'\n",
    "dict = unpickle(file_benign)\n",
    "model = ResNet18(10)\n",
    "model.cuda()\n",
    "\n",
    "model.load_state_dict(params)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2,\n",
    "                                                momentum=0.09,\n",
    "                                                weight_decay=0.4)\n",
    "\n",
    "fo = open(file_benign, 'rb')\n",
    "label = pickle.load(fo, encoding='latin1')\n",
    "fo.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_benign = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        num_random = random.randint(1,3333)\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+num_random], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_benign[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_benign[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_benign)\n",
    "        sum = sum + EntropySum_benign[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "# print(EntropySum_benign)\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在poison下信息熵均值为 -0.8485037518674508\n",
    "# 100张 poison + 10次混合其他图片 在poison下信息熵均值为 -0.7518131062481552\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在patch下信息熵均值为 8.130794444084168\n",
    "# 100张 patch + 10次混合其他图片 在patch下信息熵均值为 7.389559324502945\n",
    "dict = unpickle(file_attack)\n",
    "f1 = open(file_attack, 'rb')\n",
    "label = pickle.load(f1, encoding='latin1')\n",
    "f1.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack)\n",
    "        sum = sum + EntropySum_attack[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "dict = unpickle(file_attack_poison)\n",
    "f2 = open(file_attack_poison, 'rb')\n",
    "label = pickle.load(f2, encoding='latin1')\n",
    "f2.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_poison = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_poison[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_poison[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_poison)\n",
    "        sum = sum + EntropySum_attack_poison[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "dict = unpickle(file_attack_DBA)\n",
    "f2 = open(file_attack_DBA, 'rb')\n",
    "label = pickle.load(f2, encoding='latin1')\n",
    "f2.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_DBA = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_DBA[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_DBA[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_DBA)\n",
    "        sum = sum + EntropySum_attack_DBA[k * 10 + i]\n",
    "print(sum/100/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 30\n",
    "dpi = 600\n",
    "alpha_b = 1\n",
    "alpha = 0.8\n",
    "color_benign = '#32B897'\n",
    "color_patch = '#FFBE7A'\n",
    "color_poison = '#FA7F6F'\n",
    "color_DBA = '#BEB8DC'\n",
    "\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\cifar10-STRIP/SAB-benign.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack, bins, weights=np.ones(len(EntropySum_attack)) / len(EntropySum_attack), color = color_patch, alpha=alpha, label='with BadNets')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and BadNets data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\cifar10-STRIP/SAB-benign2BadNets.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_poison, bins, weights=np.ones(len(EntropySum_attack_poison)) / len(EntropySum_attack_poison), color = color_poison, alpha=alpha, label='with SAB')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and SAB data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\cifar10-STRIP/SAB-benign2SAB.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_DBA, bins, weights=np.ones(len(EntropySum_attack_DBA)) / len(EntropySum_attack_DBA), color = color_DBA, alpha=alpha, label='with DBA')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and DBA data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\cifar10-STRIP/poison-benign2DBA.tiff\")\n",
    "png1.close()\n",
    "plt.show()\n",
    "\n",
    "# org && org+trigger 的熵 对比，poison差别不大，patch趋势差别很大，\n",
    "# no attack 和 poison 和 patch在benign数据下的熵的对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBA model\n",
    "params = torch.load(\"D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\SAVE_MODEL\\cifar10-DBA-DP-attacknum200\\Backdoor_model_cifar10_resnet_maskRatio1.0_Snorm_0.2_checkpoint_model_epoch_3800.pth\")\n",
    "\n",
    "file_benign = 'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py/test_batch'\n",
    "file_attack = 'D:\\code\\code_xwd\\dataset\\patch_cifar10/test_batch'\n",
    "file_attack_poison = 'D:\\code\\code_xwd\\dataset\\poison_cifar10/test_batch'\n",
    "file_attack_DBA = 'D:\\code\\code_xwd\\dataset\\DBA_cifar10/test_batch'\n",
    "dict = unpickle(file_benign)\n",
    "model = ResNet18(10)\n",
    "model.cuda()\n",
    "\n",
    "model.load_state_dict(params)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2,\n",
    "                                                momentum=0.09,\n",
    "                                                weight_decay=0.4)\n",
    "\n",
    "fo = open(file_benign, 'rb')\n",
    "label = pickle.load(fo, encoding='latin1')\n",
    "fo.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_benign = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        num_random = random.randint(1,3333)\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+num_random], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_benign[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_benign[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_benign)\n",
    "        sum = sum + EntropySum_benign[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "# print(EntropySum_benign)\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在poison下信息熵均值为 -0.8485037518674508\n",
    "# 100张 poison + 10次混合其他图片 在poison下信息熵均值为 -0.7518131062481552\n",
    "\n",
    "# 100张 benign + 10次混合其他图片 在patch下信息熵均值为 8.130794444084168\n",
    "# 100张 patch + 10次混合其他图片 在patch下信息熵均值为 7.389559324502945\n",
    "dict = unpickle(file_attack)\n",
    "f1 = open(file_attack, 'rb')\n",
    "label = pickle.load(f1, encoding='latin1')\n",
    "f1.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack)\n",
    "        sum = sum + EntropySum_attack[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "dict = unpickle(file_attack_poison)\n",
    "f2 = open(file_attack_poison, 'rb')\n",
    "label = pickle.load(f2, encoding='latin1')\n",
    "f2.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_poison = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_poison[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_poison[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_poison)\n",
    "        sum = sum + EntropySum_attack_poison[k * 10 + i]\n",
    "print(sum/100/10)\n",
    "\n",
    "dict = unpickle(file_attack_DBA)\n",
    "f2 = open(file_attack_DBA, 'rb')\n",
    "label = pickle.load(f2, encoding='latin1')\n",
    "f2.close()\n",
    "labels = label.get(\"labels\")\n",
    "\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "sum = 0\n",
    "\n",
    "EntropySum_attack_DBA = [0] * 1000\n",
    "for k in range (0, 100):\n",
    "    # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "    # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "    image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "    img32 = cv.cvtColor(np.array(img32), cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for i in range(10):\n",
    "        image_trigger = np.reshape(dict.get(\"data\")[i+3333], (3, 32, 32))\n",
    "        r = image_trigger[0, :, :]\n",
    "        g = image_trigger[1, :, :]\n",
    "        b = image_trigger[2, :, :]\n",
    "        image_trigger = np.array(cv.merge([r, g, b]))\n",
    "        image_trigger = cv.cvtColor(np.array(image_trigger), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        img32Ptrigger = superimpose(np.array(img32), image_trigger) # 需要传入(32, 32, 3)\n",
    "        img32Ptrigger = PIL.Image.fromarray(img32Ptrigger)\n",
    "        \n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32Ptrigger).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        output = model(normed_img).cpu().detach()\n",
    "        # print(output)\n",
    "        EntropySum_attack_DBA[k * 10 + i] = -np.nansum(output*np.log2(output))\n",
    "        # EntropySum_attack_DBA[k * 10 + i] = int(output.data.max(1)[1])  # get the index of the max log-probability\n",
    "        # print(EntropySum_attack_DBA)\n",
    "        sum = sum + EntropySum_attack_DBA[k * 10 + i]\n",
    "print(sum/100/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 30\n",
    "dpi = 600\n",
    "alpha_b = 1\n",
    "alpha = 0.8\n",
    "color_benign = '#32B897'\n",
    "color_patch = '#FFBE7A'\n",
    "color_poison = '#FA7F6F'\n",
    "color_DBA = '#BEB8DC'\n",
    "\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\cifar10-STRIP/DBA-benign.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack, bins, weights=np.ones(len(EntropySum_attack)) / len(EntropySum_attack), color = color_patch, alpha=alpha, label='with BadNets')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and BadNets data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\cifar10-STRIP/DBA-benign2BadNets.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_poison, bins, weights=np.ones(len(EntropySum_attack_poison)) / len(EntropySum_attack_poison), color = color_poison, alpha=alpha, label='with SAB')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and SAB data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\cifar10-STRIP/DBA-benign2SAB.tiff\")\n",
    "png1.close()\n",
    "\n",
    "plt.figure(dpi=dpi)\n",
    "plt.hist(EntropySum_benign, bins, weights=np.ones(len(EntropySum_benign)) / len(EntropySum_benign), color = color_benign, alpha=alpha_b, label='without attack')\n",
    "plt.hist(EntropySum_attack_DBA, bins, weights=np.ones(len(EntropySum_attack_DBA)) / len(EntropySum_attack_DBA), color = color_DBA, alpha=alpha, label='with DBA')\n",
    "# plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
    "plt.legend(loc='upper right', fontsize = 10)\n",
    "plt.ylabel('Probability (%)', fontsize = 10)\n",
    "plt.title('normalized entropy of benign and DBA data', fontsize = 10)\n",
    "plt.tick_params(labelsize=10)\n",
    "fig1 = plt.gcf()\n",
    "png1 = io.BytesIO()\n",
    "plt.savefig(png1, format=\"png\", dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "png2 = Image.open(png1)\n",
    "# Save as TIFF\n",
    "png2.save(\"F:\\exp_org_pic\\cifar10-STRIP/DBA-benign2DBA.tiff\")\n",
    "png1.close()\n",
    "plt.show()\n",
    "\n",
    "# org && org+trigger 的熵 对比，poison差别不大，patch趋势差别很大，\n",
    "# no attack 和 poison 和 patch在benign数据下的熵的对比"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('xwdneurotoxin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfb794e02b2ed94ec65849335775c94d5008fa960a3e751499eb361e153205e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
